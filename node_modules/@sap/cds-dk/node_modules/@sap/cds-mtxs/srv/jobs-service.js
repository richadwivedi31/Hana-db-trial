const cds = require('@sap/cds/lib'), { uuid } = cds.utils
const LOG = cds.log('mtx')

const DeploymentService = 'cds.xt.DeploymentService'
const Jobs = 'cds.xt.Jobs', Tasks = 'cds.xt.Tasks'

const t0 = cds.env.requires.multitenancy.t0 ?? 't0'

const {
  clusterSize = 1, workerSize = 1, poolSize = 1
} = cds.env.requires.multitenancy.jobs ?? cds.env.requires['cds.xt.SaasProvisioningService']?.jobs ?? {}

const RUNNING = 'RUNNING', FINISHED = 'FINISHED', FAILED = 'FAILED'

module.exports = class JobsService extends cds.ApplicationService {

  async enqueue(clusters, op, args = [], onJobDone) {
    const _args = args.length > 0 ? ['with args', args.filter(Boolean)] : []
    LOG.info(`enqueuing '${op}' job for`, clusters, ..._args)

    const job_ID = uuid()
    const job = { ID: job_ID, createdAt: (new Date).toISOString(), op }
    await cds.tx({ tenant: t0 }, tx => tx.run(INSERT.into(Jobs, job)))

    const jobs = clusters.map(cluster => Array.from(cluster).map(tenant => ({ job_ID, ID: uuid(), tenant, op })))
    const tasks = jobs.flat()

    await cds.tx({ tenant: t0 }, tx => tx.run(INSERT.into(Tasks, tasks)))

    const ds = await cds.connect.to(DeploymentService)
    const tx = ds.tx(cds.context)

    _nextJob(jobs, task => tx[op](task.tenant, ...args), onJobDone)
      .catch(LOG.error)

    const url = process.env.VCAP_APPLICATION ? 'https://' + JSON.parse(process.env.VCAP_APPLICATION).uris?.[0] : cds.server.url
    cds.context.http?.res.set('Location', `${url}/-/cds/jobs/pollJob(ID='${job_ID}')`)
    cds.context.http?.res.set('x-job-id', job_ID)
    cds.context.http?.res.status(202)
    return {
      ...job,
      tenants: Object.fromEntries(tasks.map(task =>
        [task.tenant, { ...task, job_ID: undefined, tenant: undefined, op: undefined }]
      ))
    }
  }

  async pollJob(ID) {
    const job = await cds.tx({ tenant: t0 }, tx =>
      tx.run(SELECT.one.from(Jobs).where({ ID }))
    )
    if (!job) cds.error(`No job found for ID ${ID}`, { status: 404 })
    let tenants
    if (job.status ?? job.STATUS in { FINISHED: 1, FAILED: 1 }) {
      tenants = Object.fromEntries((await cds.tx({ tenant: t0 }, tx =>
        tx.run(SELECT.from(Tasks).where({ job_ID: job.ID }))
      )).map(task => [task.tenant ?? task.TENANT, {
        status: task.status ?? task.STATUS,
        error: task.error ?? task.ERROR ?? undefined
      }]))
    }
    return {
      status: job.status ?? job.STATUS,
      op: job.op ?? job.OP,
      tenants
    }
  }

  async pollTask(ID) {
    const task = await cds.tx({ tenant: t0 }, tx =>
      tx.run(SELECT.one.from(Tasks).where({ ID }))
    )
    return {
      status: task.status ?? task.STATUS,
      op: task.op ?? task.OP,
      error: task.error ?? task.ERROR
    }
  }
}

async function limiter(limit, payloads, fn, asTask = false) {
  const pending = [], all = []
  for (const payload of payloads) {
    const execute = asTask ? _nextTask(payload, fn(payload)) : fn(payload)
    all.push(execute)
    const executeAndRemove = execute.then(() => pending.splice(pending.indexOf(executeAndRemove), 1))
    pending.push(executeAndRemove)
    if (pending.length >= limit) {
      await Promise.race(pending)  // eslint-disable-line no-await-in-loop
    }
  }
  return Promise.allSettled(all)
}

async function _nextJob(clusters, fn, onJobDone) {
  if (clusters.length > 1) {
    await limiter(clusterSize, clusters, cluster => limiter(workerSize ?? poolSize, Array.from(cluster), fn, true))
  } else {
    await limiter(workerSize ?? poolSize, Array.from(clusters[0]), fn, true)
  }

  const { job_ID } = clusters.flat()[0] // all tasks have the same job ID -> just take the first
  const failed = await cds.tx({ tenant: t0 }, tx =>
    tx.run(SELECT.one.from(Tasks).where ({ job_ID, and: { status: FAILED }}))
  )
  const running = await cds.tx({ tenant: t0 }, tx =>
    tx.run(SELECT.one.from(Tasks).where ({ job_ID, and: { status: RUNNING }}))
  )

  if (failed && onJobDone) {
    await onJobDone(failed.error ?? failed.ERROR)
  } else if (!running && !failed) {
    await cds.tx({ tenant: t0 }, tx =>
      tx.run(UPDATE(Jobs, { ID: job_ID }).with({ status: FINISHED }))
    )
    if (onJobDone) await onJobDone()
  }
}

async function _nextTask(task, _fn) {
  const { job_ID, ID, tenant } = task
  let hasErrored = false
  try {
    return await _fn
  } catch (e) {
    LOG.error(e)
    hasErrored = true
    await cds.tx({ tenant: t0 }, tx =>
      tx.run(UPDATE(Tasks, { ID, tenant }).with({ status: FAILED, error: e.message }))
    )
    await cds.tx({ tenant: t0 }, tx =>
      tx.run(UPDATE(Jobs, { ID: job_ID }).with({ status: FAILED }))
    )
  } finally {
    if (!hasErrored) {
      await cds.tx({ tenant: t0 }, tx =>
        tx.run(UPDATE(Tasks, { ID, tenant }).with({ status: FINISHED }))
      )
    }
  }
}

// Cleanup finished/failed jobs
const jobCleanup = setInterval(async () => {
  const cutoff = new Date(new Date - (cds.env.requires.multitenancy.jobCleanupAge ?? 1000 * 60 * 60 * 24)) // a day
  await cds.tx({ tenant: t0 },
    tx => tx.run(DELETE.from(Jobs, { status: FAILED, or: { status: FINISHED, and: { createdAt: { '<': cutoff.toISOString() }}}}))
  )
}, cds.env.requires.multitenancy.jobCleanupInterval ?? 1000 * 60 * 60 * 24) // once a day
cds.on('shutdown', () => clearInterval(jobCleanup))

// Cleanup stale jobs
const jobCleanupStale = setInterval(async () => {
  const cutoff = new Date(new Date - (cds.env.requires.multitenancy.jobCleanupAgeStale ?? 1000 * 60 * 60 * 24 * 7)) // a week
  await cds.tx({ tenant: t0 },
    tx => tx.run(DELETE.from(Jobs, { createdAt: { '<': cutoff.toISOString() }}))
  )
}, cds.env.requires.multitenancy.jobCleanupIntervalStale ?? 1000 * 60 * 60 * 24 * 7) // once a week
cds.on('shutdown', () => clearInterval(jobCleanupStale))
